!pip install colab-xterm


%load_ext colabxterm



%xterm


v

curl -fsSL https://ollama.com/install.sh | sh

curl -fsSL https://ollama.com/install.sh | sh


pip install ollama


import ollama

prompt  = "what is the capital of France"



response = ollama.chat(model="llama3.2", messages=[{"role": "user", "content": prompt}])

response = ollama.chat(model="deepseek-r1", messages=[{"role": "user", "content": prompt}])


print(response['message']['content'])



